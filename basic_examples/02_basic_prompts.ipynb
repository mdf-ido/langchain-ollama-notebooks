{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Prompts and Prompt Engineering\n",
    "\n",
    "This notebook demonstrates prompt engineering techniques using LangChain with Ollama models.\n",
    "\n",
    "**What you'll learn:**\n",
    "- Creating and using prompt templates\n",
    "- Prompt engineering best practices\n",
    "- Different prompting techniques\n",
    "- Testing and comparing prompts\n",
    "- Prompt optimization strategies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "import sys\n",
    "sys.path.append('..')  # Add parent directory to path\n",
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.schema import SystemMessage, HumanMessage\n",
    "from config import config\n",
    "\n",
    "print(\"üéØ Setting up Prompt Engineering with LangChain + Ollama...\")\n",
    "print(f\"Using model: {config.default_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LLM\n",
    "llm = ChatOllama(\n",
    "    model=config.default_model,\n",
    "    base_url=config.ollama_base_url,\n",
    "    temperature=0.7,\n",
    "    max_tokens=500\n",
    ")\n",
    "\n",
    "print(\"‚úÖ ChatOllama initialized successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Basic Prompt Templates\n",
    "print(\"üìù Creating and testing basic prompt templates...\")\n",
    "\n",
    "# Simple string template\n",
    "simple_template = PromptTemplate(\n",
    "    input_variables=[\"topic\", \"audience\"],\n",
    "    template=\"Explain {topic} in simple terms for {audience}.\"\n",
    ")\n",
    "\n",
    "# Generate prompt\n",
    "prompt = simple_template.format(topic=\"machine learning\", audience=\"beginners\")\n",
    "print(f\"Generated prompt: {prompt}\")\n",
    "\n",
    "# Test with LLM\n",
    "response = llm.invoke(prompt)\n",
    "print(f\"\\nü§ñ Response:\")\n",
    "print(response.content)\n",
    "print(\"\\n\" + \"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Chat Prompt Templates\n",
    "print(\"üí¨ Working with Chat Prompt Templates...\")\n",
    "\n",
    "# Create a chat prompt template with system and human messages\n",
    "chat_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a {role} who specializes in {domain}. Always provide practical advice.\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "# Test the template\n",
    "messages = chat_template.format_messages(\n",
    "    role=\"data scientist\",\n",
    "    domain=\"Python programming\",\n",
    "    question=\"What's the best way to handle missing data in a dataset?\"\n",
    ")\n",
    "\n",
    "print(\"Generated messages:\")\n",
    "for msg in messages:\n",
    "    print(f\"  {msg.__class__.__name__}: {msg.content}\")\n",
    "\n",
    "# Get response\n",
    "response = llm.invoke(messages)\n",
    "print(f\"\\nü§ñ Response:\")\n",
    "print(response.content)\n",
    "print(\"\\n\" + \"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Different Prompting Techniques\n",
    "print(\"üß† Testing different prompting techniques...\")\n",
    "\n",
    "# Few-shot prompting\n",
    "few_shot_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an expert at categorizing text. Here are some examples:\"),\n",
    "    (\"human\", \"Text: 'I love this movie!' Category: Positive\"),\n",
    "    (\"assistant\", \"Understood. That's a positive sentiment.\"),\n",
    "    (\"human\", \"Text: 'This food is terrible.' Category: Negative\"),\n",
    "    (\"assistant\", \"Understood. That's a negative sentiment.\"),\n",
    "    (\"human\", \"Text: '{text}' Category: ?\")\n",
    "])\n",
    "\n",
    "# Test few-shot prompting\n",
    "test_text = \"The weather today is okay, nothing special.\"\n",
    "messages = few_shot_template.format_messages(text=test_text)\n",
    "\n",
    "response = llm.invoke(messages)\n",
    "print(f\"Few-shot prompting test:\")\n",
    "print(f\"Text: '{test_text}'\")\n",
    "print(f\"ü§ñ Response: {response.content}\")\n",
    "print(\"\\n\" + \"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Chain of Thought Prompting\n",
    "print(\"üîó Testing Chain of Thought prompting...\")\n",
    "\n",
    "cot_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a logical problem solver. Always show your reasoning step by step.\"),\n",
    "    (\"human\", \"\"\"{problem}\n",
    "    \n",
    "Please solve this step by step:\n",
    "1. First, identify what we know\n",
    "2. Then, determine what we need to find\n",
    "3. Finally, work through the solution\n",
    "\"\"\")\n",
    "])\n",
    "\n",
    "# Test with a simple math problem\n",
    "problem = \"If a train travels 60 miles in 90 minutes, what is its speed in miles per hour?\"\n",
    "messages = cot_template.format_messages(problem=problem)\n",
    "\n",
    "response = llm.invoke(messages)\n",
    "print(f\"Chain of Thought test:\")\n",
    "print(f\"Problem: {problem}\")\n",
    "print(f\"\\nü§ñ Step-by-step response:\")\n",
    "print(response.content)\n",
    "print(\"\\n\" + \"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Prompt Testing and Comparison\n",
    "print(\"‚öñÔ∏è Comparing different prompt approaches...\")\n",
    "\n",
    "# Define different approaches for the same task\n",
    "task = \"Write a brief description of Python programming language\"\n",
    "\n",
    "approaches = {\n",
    "    \"Direct\": \"Write a brief description of Python programming language.\",\n",
    "    \n",
    "    \"With Context\": \"\"\"You are a technical writer for beginners.\n",
    "Write a brief description of Python programming language.\"\"\",\n",
    "    \n",
    "    \"Structured\": \"\"\"Write a brief description of Python programming language.\n",
    "Please include:\n",
    "- What Python is\n",
    "- Its main uses\n",
    "- Why it's popular\n",
    "Keep it under 100 words.\"\"\",\n",
    "    \n",
    "    \"With Examples\": \"\"\"Write a brief description of Python programming language.\n",
    "Include a simple code example to illustrate its simplicity.\n",
    "Target audience: complete beginners.\"\"\"\n",
    "}\n",
    "\n",
    "# Test each approach\n",
    "results = {}\n",
    "\n",
    "for approach_name, prompt_text in approaches.items():\n",
    "    print(f\"\\nüß™ Testing: {approach_name}\")\n",
    "    print(f\"Prompt: {prompt_text[:80]}{'...' if len(prompt_text) > 80 else ''}\")\n",
    "    \n",
    "    try:\n",
    "        response = llm.invoke(prompt_text)\n",
    "        results[approach_name] = response.content\n",
    "        print(f\"‚úÖ Length: {len(response.content)} characters\")\n",
    "        print(f\"üìù Response: {response.content[:100]}...\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        results[approach_name] = f\"Error: {e}\"\n",
    "\n",
    "print(\"\\n\" + \"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Dynamic Prompt Templates\n",
    "print(\"üîÑ Creating dynamic, reusable prompt templates...\")\n",
    "\n",
    "# Template for code explanation\n",
    "code_explanation_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are an expert {language} programmer and teacher.\n",
    "Explain code clearly and concisely for {skill_level} developers.\n",
    "Always include:\n",
    "- What the code does\n",
    "- How it works\n",
    "- Any important concepts\"\"\"),\n",
    "    (\"human\", \"Please explain this {language} code:\\n\\n{code}\")\n",
    "])\n",
    "\n",
    "# Test with Python code\n",
    "python_code = \"\"\"\n",
    "def fibonacci(n):\n",
    "    if n <= 1:\n",
    "        return n\n",
    "    return fibonacci(n-1) + fibonacci(n-2)\n",
    "\n",
    "print(fibonacci(10))\n",
    "\"\"\"\n",
    "\n",
    "messages = code_explanation_template.format_messages(\n",
    "    language=\"Python\",\n",
    "    skill_level=\"beginner\",\n",
    "    code=python_code.strip()\n",
    ")\n",
    "\n",
    "response = llm.invoke(messages)\n",
    "print(f\"Code explanation test:\")\n",
    "print(f\"ü§ñ Explanation:\")\n",
    "print(response.content)\n",
    "print(\"\\n\" + \"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Prompt Optimization Function\n",
    "print(\"‚ö° Creating a prompt optimization helper...\")\n",
    "\n",
    "def optimize_prompt(base_prompt, target_length=None, style=\"professional\", temperature=0.7):\n",
    "    \"\"\"Helper function to create optimized prompts.\"\"\"\n",
    "    \n",
    "    # Style guides\n",
    "    style_guides = {\n",
    "        \"professional\": \"Be professional, clear, and concise.\",\n",
    "        \"casual\": \"Be friendly, conversational, and approachable.\",\n",
    "        \"technical\": \"Be precise, detailed, and use technical terminology appropriately.\",\n",
    "        \"creative\": \"Be imaginative, engaging, and think outside the box.\"\n",
    "    }\n",
    "    \n",
    "    # Build optimized prompt\n",
    "    optimized = f\"{style_guides.get(style, style_guides['professional'])}\\n\\n\"\n",
    "    optimized += base_prompt\n",
    "    \n",
    "    if target_length:\n",
    "        optimized += f\"\\n\\nPlease keep your response to approximately {target_length} words.\"\n",
    "    \n",
    "    return optimized\n",
    "\n",
    "# Test the optimization function\n",
    "base = \"Explain the difference between machine learning and artificial intelligence.\"\n",
    "\n",
    "styles_to_test = [\"professional\", \"casual\", \"technical\"]\n",
    "\n",
    "for style in styles_to_test:\n",
    "    print(f\"\\nüé® Testing {style} style:\")\n",
    "    \n",
    "    optimized_prompt = optimize_prompt(base, target_length=50, style=style)\n",
    "    response = llm.invoke(optimized_prompt)\n",
    "    \n",
    "    print(f\"üìù Response ({len(response.content.split())} words): {response.content[:150]}...\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Prompt Engineering Best Practices Summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PROMPT ENGINEERING BEST PRACTICES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "best_practices = {\n",
    "    \"üìù Be Specific\": [\n",
    "        \"Use clear, specific instructions\",\n",
    "        \"Define the desired output format\",\n",
    "        \"Specify constraints (length, style, etc.)\"\n",
    "    ],\n",
    "    \"üé≠ Set Context\": [\n",
    "        \"Use system messages to set role/persona\",\n",
    "        \"Provide relevant background information\",\n",
    "        \"Define the target audience\"\n",
    "    ],\n",
    "    \"üîß Structure Prompts\": [\n",
    "        \"Break complex tasks into steps\",\n",
    "        \"Use examples (few-shot prompting)\",\n",
    "        \"Apply chain-of-thought for reasoning\"\n",
    "    ],\n",
    "    \"‚ö° Optimize Performance\": [\n",
    "        \"Test different temperature settings\",\n",
    "        \"Compare multiple approaches\",\n",
    "        \"Iterate and refine based on results\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "for category, tips in best_practices.items():\n",
    "    print(f\"\\n{category}:\")\n",
    "    for tip in tips:\n",
    "        print(f\"  ‚Ä¢ {tip}\")\n",
    "\n",
    "print(\"\\nüí° Key LangChain Templates:\")\n",
    "print(\"‚Ä¢ PromptTemplate: Simple string templates\")\n",
    "print(\"‚Ä¢ ChatPromptTemplate: Multi-message conversations\")\n",
    "print(\"‚Ä¢ SystemMessagePromptTemplate: System context\")\n",
    "print(\"‚Ä¢ HumanMessagePromptTemplate: User inputs\")\n",
    "\n",
    "print(\"\\nüöÄ Next Steps:\")\n",
    "print(\"‚Ä¢ Try advanced prompting techniques\")\n",
    "print(\"‚Ä¢ Experiment with different models\")\n",
    "print(\"‚Ä¢ Build prompt libraries for common tasks\")\n",
    "print(\"‚Ä¢ Next notebook: basic_examples/03_model_testing.ipynb\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  }
 ],\n "metadata": {\n  "kernelspec": {\n   "display_name": "Python 3",\n   "language": "python",\n   "name": "python3"\n  },\n  "language_info": {\n   "codemirror_mode": {\n    "name": "ipython",\n    "version": 3\n   },\n   "file_extension": ".py",\n   "mimetype": "text/x-python",\n   "name": "python",\n   "nbconvert_exporter": "python",\n   "pygments_lexer": "ipython3",\n   "version": "3.8.5"\n  }\n },\n "nbformat": 4,\n "nbformat_minor": 4\n}