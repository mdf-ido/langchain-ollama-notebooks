{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Setup and Validation\n",
    "\n",
    "This notebook helps you validate that your environment is properly set up for running LangChain with Ollama.\n",
    "\n",
    "**Prerequisites:**\n",
    "- Python 3.8+\n",
    "- Ollama installed and running locally\n",
    "- Required packages installed (see requirements.txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Python Version Check\n",
    "import sys\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "\n",
    "# Check minimum version requirement\n",
    "if sys.version_info >= (3, 8):\n",
    "    print(\"‚úÖ Python version meets requirements (3.8+)\")\n",
    "else:\n",
    "    print(\"‚ùå Python version is too old. Please upgrade to 3.8 or newer.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Package Verification\n",
    "import pkg_resources\n",
    "import importlib\n",
    "\n",
    "required_packages = [\n",
    "    'langchain',\n",
    "    'langchain_ollama', \n",
    "    'numpy',\n",
    "    'pandas',\n",
    "    'requests',\n",
    "    'python-dotenv'\n",
    "]\n",
    "\n",
    "print(\"Checking required packages...\")\n",
    "missing_packages = []\n",
    "\n",
    "for package in required_packages:\n",
    "    try:\n",
    "        # Try to import the package\n",
    "        importlib.import_module(package.replace('-', '_'))\n",
    "        # Get version info\n",
    "        try:\n",
    "            version = pkg_resources.get_distribution(package).version\n",
    "            print(f\"‚úÖ {package}: {version}\")\n",
    "        except:\n",
    "            print(f\"‚úÖ {package}: installed (version unknown)\")\n",
    "    except ImportError:\n",
    "        print(f\"‚ùå {package}: not installed\")\n",
    "        missing_packages.append(package)\n",
    "\n",
    "if missing_packages:\n",
    "    print(f\"\\n‚ö†Ô∏è Missing packages: {', '.join(missing_packages)}\")\n",
    "    print(\"Install with: pip install -r requirements.txt\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ All required packages are installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Configuration Loading\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('..')  # Add parent directory to path\n",
    "\n",
    "try:\n",
    "    from config import config\n",
    "    print(\"‚úÖ Configuration loaded successfully\")\n",
    "    print(f\"   Ollama URL: {config.ollama_base_url}\")\n",
    "    print(f\"   Default model: {config.default_model}\")\n",
    "    print(f\"   Temperature: {config.temperature}\")\n",
    "    print(f\"   Max tokens: {config.max_tokens}\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Error loading configuration: {e}\")\n",
    "    print(\"Make sure config.py is in the parent directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Ollama Connection Testing\n",
    "import requests\n",
    "from config import config\n",
    "\n",
    "print(\"Testing Ollama connection...\")\n",
    "try:\n",
    "    # Test basic connection\n",
    "    response = requests.get(f\"{config.ollama_base_url}/api/tags\", timeout=10)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        print(\"‚úÖ Connection to Ollama successful\")\n",
    "        \n",
    "        # Show available models\n",
    "        data = response.json()\n",
    "        models = [model['name'] for model in data.get('models', [])]\n",
    "        \n",
    "        if models:\n",
    "            print(f\"   Available models: {', '.join(models)}\")\n",
    "            \n",
    "            if config.default_model in [model.split(':')[0] for model in models]:\n",
    "                print(f\"‚úÖ Default model '{config.default_model}' is available\")\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è Default model '{config.default_model}' not found\")\n",
    "                print(f\"   You may need to run: ollama pull {config.default_model}\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è No models found. Pull a model with: ollama pull llama2\")\n",
    "    else:\n",
    "        print(f\"‚ùå Failed to connect to Ollama, status code: {response.status_code}\")\n",
    "        \n",
    "except requests.exceptions.ConnectionError:\n",
    "    print(\"‚ùå Connection failed - Is Ollama running?\")\n",
    "    print(\"   Start Ollama with: ollama serve\")\n",
    "except requests.exceptions.Timeout:\n",
    "    print(\"‚ùå Connection timeout - Ollama may be starting up\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error connecting to Ollama: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. LangChain Integration Test\n",
    "print(\"Testing LangChain + Ollama integration...\")\n",
    "\n",
    "try:\n",
    "    from langchain_ollama import ChatOllama\n",
    "    \n",
    "    # Create a simple LLM instance\n",
    "    llm = ChatOllama(\n",
    "        model=config.default_model,\n",
    "        base_url=config.ollama_base_url,\n",
    "        temperature=0.1  # Low temperature for consistent testing\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ ChatOllama instance created successfully\")\n",
    "    \n",
    "    # Test a simple prompt\n",
    "    print(\"Testing simple prompt...\")\n",
    "    response = llm.invoke(\"Hello! Please respond with just 'Hello World!'\")\n",
    "    \n",
    "    print(f\"‚úÖ Response received: {response.content[:100]}{'...' if len(response.content) > 100 else ''}\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå LangChain import error: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå LangChain integration test failed: {e}\")\n",
    "    print(\"   Make sure Ollama is running and the default model is available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Environment Summary\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ENVIRONMENT SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Python version\n",
    "python_ok = sys.version_info >= (3, 8)\n",
    "print(f\"Python version: {sys.version.split()[0]} {'‚úÖ' if python_ok else '‚ùå'}\")\n",
    "\n",
    "# Package status\n",
    "packages_ok = len(missing_packages) == 0 if 'missing_packages' in locals() else False\n",
    "print(f\"Required packages: {'‚úÖ' if packages_ok else '‚ùå'}\")\n",
    "\n",
    "# Configuration\n",
    "config_ok = 'config' in locals()\n",
    "print(f\"Configuration: {'‚úÖ' if config_ok else '‚ùå'}\")\n",
    "\n",
    "# Ollama connection\n",
    "ollama_ok = 'response' in locals() and response.status_code == 200\n",
    "print(f\"Ollama connection: {'‚úÖ' if ollama_ok else '‚ùå'}\")\n",
    "\n",
    "# LangChain integration\n",
    "langchain_ok = 'llm' in locals()\n",
    "print(f\"LangChain integration: {'‚úÖ' if langchain_ok else '‚ùå'}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "if all([python_ok, packages_ok, config_ok, ollama_ok, langchain_ok]):\n",
    "    print(\"üéâ ENVIRONMENT READY! You can proceed with the examples.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  SETUP INCOMPLETE. Please resolve the issues above.\")\n",
    "print(\"=\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}