{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Prompt Engineering Techniques\n",
    "\n",
    "This notebook demonstrates advanced prompt engineering techniques for better results with LangChain and Ollama.\n",
    "\n",
    "**What you'll learn:**\n",
    "- Advanced prompting patterns\n",
    "- Chain of thought reasoning\n",
    "- Role-based prompting\n",
    "- Prompt chaining and composition\n",
    "- Context management\n",
    "- Response validation and improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "import sys\n",
    "sys.path.append('..')  # Add parent directory to path\n",
    "\n",
    "import json\n",
    "import re\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain.schema import SystemMessage, HumanMessage, AIMessage\n",
    "from config import config\n",
    "\n",
    "print(\"üéì Advanced Prompt Engineering with LangChain + Ollama\")\n",
    "print(f\"Using model: {config.default_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LLM with optimal settings for advanced techniques\\n\n",
    "llm = ChatOllama(\\n\n",
    "    model=config.default_model,\\n\n",
    "    base_url=config.ollama_base_url,\\n\n",
    "    temperature=0.3,  # Lower temperature for more consistent reasoning\\n\n",
    "    max_tokens=1000   # Higher token limit for complex responses\\n\n",
    ")\\n\n",
    "\\n\n",
    "print(\"‚úÖ Advanced LLM configured successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Chain of Thought (CoT) Prompting\\n\n",
    "print(\"üîó Chain of Thought Prompting...\")\\n\n",
    "\\n\n",
    "def create_cot_prompt(problem, domain=\"general\"):\\n\n",
    "    \"\"\"Create a chain of thought prompt for complex problem solving.\"\"\"\\n\n",
    "    \\n\n",
    "    domain_contexts = {\\n\n",
    "        \"math\": \"You are a mathematics expert who solves problems step by step.\",\\n\n",
    "        \"programming\": \"You are a senior software engineer who analyzes code problems systematically.\",\\n\n",
    "        \"analysis\": \"You are a data analyst who breaks down complex problems methodically.\",\\n\n",
    "        \"general\": \"You are an expert problem solver who thinks step by step.\"\\n\n",
    "    }\\n\n",
    "    \\n\n",
    "    template = ChatPromptTemplate.from_messages([\\n\n",
    "        (\"system\", domain_contexts.get(domain, domain_contexts[\"general\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Role-Based Prompting with Personas\\n\n",
    "print(\"üé≠ Role-Based Prompting with Detailed Personas...\")\\n\n",
    "\\n\n",
    "def create_persona_prompt(role, task, context=None):\\n\n",
    "    \"\"\"Create a detailed persona-based prompt.\"\"\"\\n\n",
    "    \\n\n",
    "    personas = {\\n\n",
    "        \"senior_developer\": {\\n\n",
    "            \"identity\": \"You are a senior software developer with 10+ years of experience in Python, JavaScript, and system architecture.\",\\n\n",
    "            \"style\": \"You provide practical, production-ready advice with code examples.\",\\n\n",
    "            \"expertise\": \"You excel at debugging, optimization, and best practices.\"\\n\n",
    "        },\\n\n",
    "        \"data_scientist\": {\\n\n",
    "            \"identity\": \"You are an experienced data scientist with expertise in machine learning, statistics, and data analysis.\",\\n\n",
    "            \"style\": \"You explain complex concepts clearly and provide actionable insights.\",\\n\n",
    "            \"expertise\": \"You specialize in Python, R, SQL, and various ML frameworks.\"\\n\n",
    "        },\\n\n",
    "        \"tech_writer\": {\\n\n",
    "            \"identity\": \"You are a technical writer who specializes in making complex technical concepts accessible.\",\\n\n",
    "            \"style\": \"You write clearly, use analogies, and structure information logically.\",\\n\n",
    "            \"expertise\": \"You excel at documentation, tutorials, and explaining technical topics.\"\\n\n",
    "        },\\n\n",
    "        \"consultant\": {\\n\n",
    "            \"identity\": \"You are a business consultant with deep technical knowledge and strategic thinking.\",\\n\n",
    "            \"style\": \"You provide balanced analysis considering both technical and business aspects.\",\\n\n",
    "            \"expertise\": \"You excel at requirement analysis, solution design, and risk assessment.\"\\n\n",
    "        }\\n\n",
    "    }\\n\n",
    "    \\n\n",
    "    persona = personas.get(role, personas[\"consultant\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Multi-Step Reasoning with Prompt Chaining\\n\n",
    "print(\"‚õìÔ∏è Multi-Step Reasoning with Prompt Chaining...\")\\n\n",
    "\\n\n",
    "def analyze_code_quality(code_snippet):\\n\n",
    "    \"\"\"Multi-step code analysis using prompt chaining.\"\"\"\\n\n",
    "    \\n\n",
    "    # Step 1: Initial analysis\\n\n",
    "    analysis_prompt = ChatPromptTemplate.from_messages([\\n\n",
    "        (\"system\", \"You are a code reviewer. Analyze the given code for functionality, readability, and potential issues.\"),\\n\n",
    "        (\"human\", \"Analyze this Python code and identify: 1) What it does, 2) Potential issues, 3) Code quality aspects\\\\n\\\\nCode:\\\\n{code}\")\\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Context-Aware Conversation Management\\n\n",
    "print(\"üí¨ Context-Aware Conversation Management...\")\\n\n",
    "\\n\n",
    "class ContextualChat:\\n\n",
    "    \"\"\"Manages conversation context for better responses.\"\"\"\\n\n",
    "    \\n\n",
    "    def __init__(self, llm, system_prompt=None, max_history=10):\\n\n",
    "        self.llm = llm\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Response Validation and Self-Correction\\n\n",
    "print(\"‚úÖ Response Validation and Self-Correction...\")\\n\n",
    "\\n\n",
    "def validated_response(prompt, validation_criteria, max_attempts=3):\\n\n",
    "    \"\"\"Generate a response and validate it against criteria.\"\"\"\\n\n",
    "    \\n\n",
    "    for attempt in range(max_attempts):\\n\n",
    "        print(f\"  Attempt {attempt + 1}...\")\\n\n",
    "        \\n\n",
    "        # Generate response\\n\n",
    "        response = llm.invoke(prompt)\\n\n",
    "        content = response.content\\n\n",
    "        \\n\n",
    "        # Validate response\\n\n",
    "        validation_prompt = f\"\"\"\\n\n",
    "Please evaluate this response against the given criteria:\\n\n",
    "\\n\n",
    "Original Request: {prompt}\\n\n",
    "Response: {content}\\n\n",
    "Criteria: {validation_criteria}\\n\n",
    "\\n\n",
    "Does the response meet all criteria? Answer with:\\n\n",
    "- \"YES\" if it meets all criteria\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Advanced Technique Summary and Best Practices\\n\n",
    "print(\"\\\\n\" + \"=\"*60)\\n\n",
    "print(\"ADVANCED PROMPT ENGINEERING SUMMARY\")\\n\n",
    "print(\"=\"*60)\\n\n",
    "\\n\n",
    "techniques_summary = {\\n\n",
    "    \"üîó Chain of Thought\": {\\n\n",
    "        \"when\": \"Complex reasoning, math problems, multi-step analysis\",\\n\n",
    "        \"tip\": \"Use explicit step-by-step instructions and ask for verification\"\\n\n",
    "    },\\n\n",
    "    \"üé≠ Role-Based Prompting\": {\\n\n",
    "        \"when\": \"Domain-specific advice, different perspectives needed\",\\n\n",
    "        \"tip\": \"Create detailed personas with expertise and communication style\"\\n\n",
    "    },\\n\n",
    "    \"‚õìÔ∏è Prompt Chaining\": {\\n\n",
    "        \"when\": \"Multi-stage processing, complex analysis workflows\",\\n\n",
    "        \"tip\": \"Break complex tasks into sequential, focused prompts\"\\n\n",
    "    },\\n\n",
    "    \"üí¨ Context Management\": {\\n\n",
    "        \"when\": \"Long conversations, building on previous responses\",\\n\n",
    "        \"tip\": \"Maintain context but summarize when history gets long\"\\n\n",
    "    },\\n\n",
    "    \"‚úÖ Response Validation\": {\\n\n",
    "        \"when\": \"Quality assurance, specific requirements needed\",\\n\n",
    "        \"tip\": \"Define clear criteria and iterate until satisfied\"\\n\n",
    "    }\\n\n",
    "}\\n\n",
    "\\n\n",
    "for technique, info in techniques_summary.items():\\n\n",
    "    print(f\"\\\\n{technique}:\")\\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
